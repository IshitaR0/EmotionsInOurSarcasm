{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e6f4866-1d7c-452d-bfd8-061044602dbc",
   "metadata": {},
   "source": [
    "C:\\Users\\SUHAANI SACHDEVA\\OneDrive - Plaksha University\\MLPR raw data(video)\\test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "87909d8d-f442-4878-b273-15569fce6d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 16 keyframes from train_10_0\n",
      "Extracted 9 keyframes from train_10_1\n",
      "Extracted 4 keyframes from train_10_2\n",
      "Extracted 2 keyframes from train_10_3\n",
      "Extracted 7 keyframes from train_10_4\n",
      "Extracted 2 keyframes from train_11_0\n",
      "Extracted 11 keyframes from train_11_1\n",
      "Extracted 5 keyframes from train_11_2\n",
      "Extracted 2 keyframes from train_11_3\n",
      "Extracted 9 keyframes from train_11_4\n",
      "Extracted 23 keyframes from train_11_5\n",
      "Extracted 55 keyframes from train_12_0\n",
      "Extracted 4 keyframes from train_12_1\n",
      "Extracted 9 keyframes from train_12_2\n",
      "Extracted 47 keyframes from train_12_3\n",
      "Extracted 9 keyframes from train_13_0\n",
      "Extracted 22 keyframes from train_13_1\n",
      "Extracted 6 keyframes from train_13_2\n",
      "Extracted 12 keyframes from train_13_3\n",
      "Extracted 6 keyframes from train_14_0\n",
      "Extracted 0 keyframes from train_14_1\n",
      "Extracted 25 keyframes from train_14_2\n",
      "Extracted 12 keyframes from train_14_3\n",
      "Extracted 6 keyframes from train_15_0\n",
      "Extracted 5 keyframes from train_15_1\n",
      "Extracted 3 keyframes from train_15_2\n",
      "Extracted 1 keyframes from train_15_3\n",
      "Extracted 8 keyframes from train_15_4\n",
      "Extracted 16 keyframes from train_16_0\n",
      "Extracted 47 keyframes from train_16_1\n",
      "Extracted 12 keyframes from train_16_2\n",
      "Extracted 10 keyframes from train_17_0\n",
      "Extracted 13 keyframes from train_17_1\n",
      "Extracted 7 keyframes from train_17_2\n",
      "Extracted 21 keyframes from train_17_3\n",
      "Extracted 3 keyframes from train_18_0\n",
      "Extracted 18 keyframes from train_18_1\n",
      "Extracted 13 keyframes from train_19_0\n",
      "Extracted 20 keyframes from train_19_1\n",
      "Extracted 47 keyframes from train_1_0\n",
      "Extracted 21 keyframes from train_1_1\n",
      "Extracted 36 keyframes from train_1_2\n",
      "Extracted 88 keyframes from train_20_0\n",
      "Extracted 11 keyframes from train_20_1\n",
      "Extracted 7 keyframes from train_21_0\n",
      "Extracted 2 keyframes from train_21_1\n",
      "Extracted 14 keyframes from train_21_2\n",
      "Extracted 1 keyframes from train_22_0\n",
      "Extracted 0 keyframes from train_22_1\n",
      "Extracted 0 keyframes from train_22_2\n",
      "Extracted 8 keyframes from train_22_3\n",
      "Extracted 3 keyframes from train_23_0\n",
      "Extracted 23 keyframes from train_23_1\n",
      "Extracted 11 keyframes from train_23_2\n",
      "Extracted 2 keyframes from train_24_0\n",
      "Extracted 2 keyframes from train_24_1\n",
      "Extracted 2 keyframes from train_25_0\n",
      "Extracted 4 keyframes from train_25_1\n",
      "Extracted 0 keyframes from train_25_2\n",
      "Extracted 21 keyframes from train_25_3\n",
      "Extracted 4 keyframes from train_25_4\n",
      "Extracted 15 keyframes from train_25_5\n",
      "Extracted 2 keyframes from train_26_0\n",
      "Extracted 6 keyframes from train_26_1\n",
      "Extracted 8 keyframes from train_26_2\n",
      "Extracted 14 keyframes from train_26_3\n",
      "Extracted 7 keyframes from train_27_0\n",
      "Extracted 2 keyframes from train_27_1\n",
      "Extracted 0 keyframes from train_27_2\n",
      "Extracted 6 keyframes from train_27_3\n",
      "Extracted 3 keyframes from train_27_4\n",
      "Extracted 6 keyframes from train_27_5\n",
      "Extracted 13 keyframes from train_27_6\n",
      "Extracted 17 keyframes from train_28_0\n",
      "Extracted 12 keyframes from train_28_1\n",
      "Extracted 10 keyframes from train_28_2\n",
      "Extracted 5 keyframes from train_28_3\n",
      "Extracted 3 keyframes from train_29_0\n",
      "Extracted 4 keyframes from train_29_1\n",
      "Extracted 28 keyframes from train_29_2\n",
      "Extracted 12 keyframes from train_29_3\n",
      "Extracted 3 keyframes from train_29_4\n",
      "Extracted 2 keyframes from train_29_5\n",
      "Extracted 10 keyframes from train_29_6\n",
      "Extracted 5 keyframes from train_29_7\n",
      "Extracted 0 keyframes from train_2_0\n",
      "Extracted 11 keyframes from train_2_1\n",
      "Extracted 2 keyframes from train_2_2\n",
      "Extracted 2 keyframes from train_2_3\n",
      "Extracted 6 keyframes from train_30_0\n",
      "Extracted 4 keyframes from train_30_1\n",
      "Extracted 29 keyframes from train_31_0\n",
      "Extracted 23 keyframes from train_31_1\n",
      "Extracted 7 keyframes from train_31_2\n",
      "Extracted 3 keyframes from train_32_0\n",
      "Extracted 4 keyframes from train_32_1\n",
      "Extracted 0 keyframes from train_32_2\n",
      "Extracted 2 keyframes from train_32_3\n",
      "Extracted 4 keyframes from train_32_4\n",
      "Extracted 23 keyframes from train_32_5\n",
      "Extracted 15 keyframes from train_33_0\n",
      "Extracted 4 keyframes from train_33_1\n",
      "Extracted 38 keyframes from train_33_2\n",
      "Extracted 24 keyframes from train_34_0\n",
      "Extracted 10 keyframes from train_34_1\n",
      "Extracted 12 keyframes from train_34_2\n",
      "Extracted 4 keyframes from train_34_3\n",
      "Extracted 27 keyframes from train_35_0\n",
      "Extracted 0 keyframes from train_35_1\n",
      "Extracted 31 keyframes from train_36_0\n",
      "Extracted 17 keyframes from train_37_0\n",
      "Extracted 10 keyframes from train_37_1\n",
      "Extracted 88 keyframes from train_37_2\n",
      "Extracted 20 keyframes from train_37_3\n",
      "Extracted 26 keyframes from train_38_0\n",
      "Extracted 58 keyframes from train_38_1\n",
      "Extracted 23 keyframes from train_38_2\n",
      "Extracted 22 keyframes from train_39_0\n",
      "Extracted 5 keyframes from train_39_1\n",
      "Extracted 37 keyframes from train_39_2\n",
      "Extracted 21 keyframes from train_3_0\n",
      "Extracted 8 keyframes from train_3_1\n",
      "Extracted 83 keyframes from train_3_2\n",
      "Extracted 0 keyframes from train_40_0\n",
      "Extracted 9 keyframes from train_40_1\n",
      "Extracted 22 keyframes from train_40_2\n",
      "Extracted 3 keyframes from train_40_3\n",
      "Extracted 21 keyframes from train_40_4\n",
      "Extracted 4 keyframes from train_41_0\n",
      "Extracted 4 keyframes from train_41_1\n",
      "Extracted 6 keyframes from train_41_2\n",
      "Extracted 4 keyframes from train_42_0\n",
      "Extracted 8 keyframes from train_42_1\n",
      "Extracted 2 keyframes from train_42_2\n",
      "Extracted 3 keyframes from train_43_0\n",
      "Extracted 3 keyframes from train_43_1\n",
      "Extracted 18 keyframes from train_43_2\n",
      "Extracted 1 keyframes from train_43_3\n",
      "Extracted 11 keyframes from train_43_4\n",
      "Extracted 26 keyframes from train_43_5\n",
      "Extracted 2 keyframes from train_44_0\n",
      "Extracted 2 keyframes from train_44_1\n",
      "Extracted 4 keyframes from train_44_2\n",
      "Extracted 0 keyframes from train_45_0\n",
      "Extracted 0 keyframes from train_45_1\n",
      "Extracted 0 keyframes from train_46_0\n",
      "Extracted 6 keyframes from train_46_1\n",
      "Extracted 16 keyframes from train_46_2\n",
      "Extracted 25 keyframes from train_46_3\n",
      "Extracted 0 keyframes from train_46_4\n",
      "Extracted 5 keyframes from train_46_5\n",
      "Extracted 8 keyframes from train_46_6\n",
      "Extracted 2 keyframes from train_46_7\n",
      "Extracted 0 keyframes from train_46_8\n",
      "Extracted 19 keyframes from train_47_0\n",
      "Extracted 5 keyframes from train_47_1\n",
      "Extracted 7 keyframes from train_47_2\n",
      "Extracted 0 keyframes from train_48_0\n",
      "Extracted 2 keyframes from train_48_1\n",
      "Extracted 8 keyframes from train_48_2\n",
      "Extracted 3 keyframes from train_48_3\n",
      "Extracted 6 keyframes from train_48_4\n",
      "Extracted 13 keyframes from train_48_5\n",
      "Extracted 2 keyframes from train_48_6\n",
      "Extracted 3 keyframes from train_49_0\n",
      "Extracted 42 keyframes from train_49_1\n",
      "Extracted 36 keyframes from train_4_0\n",
      "Extracted 5 keyframes from train_4_1\n",
      "Extracted 0 keyframes from train_4_2\n",
      "Extracted 22 keyframes from train_4_3\n",
      "Extracted 4 keyframes from train_50_0\n",
      "Extracted 2 keyframes from train_50_1\n",
      "Extracted 4 keyframes from train_50_2\n",
      "Extracted 3 keyframes from train_51_0\n",
      "Extracted 51 keyframes from train_51_1\n",
      "Extracted 15 keyframes from train_52_0\n",
      "Extracted 3 keyframes from train_52_1\n",
      "Extracted 13 keyframes from train_52_2\n",
      "Extracted 7 keyframes from train_52_3\n",
      "Extracted 6 keyframes from train_52_4\n",
      "Extracted 13 keyframes from train_53_0\n",
      "Extracted 14 keyframes from train_53_1\n",
      "Extracted 3 keyframes from train_53_2\n",
      "Extracted 4 keyframes from train_54_0\n",
      "Extracted 2 keyframes from train_54_1\n",
      "Extracted 4 keyframes from train_54_2\n",
      "Extracted 2 keyframes from train_54_3\n",
      "Extracted 4 keyframes from train_54_4\n",
      "Extracted 4 keyframes from train_54_5\n",
      "Extracted 13 keyframes from train_55_0\n",
      "Extracted 7 keyframes from train_55_1\n",
      "Extracted 6 keyframes from train_55_2\n",
      "Extracted 6 keyframes from train_56_0\n",
      "Extracted 6 keyframes from train_56_1\n",
      "Extracted 13 keyframes from train_56_2\n",
      "Extracted 6 keyframes from train_56_3\n",
      "Extracted 47 keyframes from train_56_4\n",
      "Extracted 22 keyframes from train_56_5\n",
      "Extracted 11 keyframes from train_57_0\n",
      "Extracted 3 keyframes from train_57_1\n",
      "Extracted 27 keyframes from train_57_2\n",
      "Extracted 15 keyframes from train_57_3\n",
      "Extracted 2 keyframes from train_58_0\n",
      "Extracted 6 keyframes from train_58_1\n",
      "Extracted 39 keyframes from train_58_2\n",
      "Extracted 5 keyframes from train_59_0\n",
      "Extracted 13 keyframes from train_59_1\n",
      "Extracted 21 keyframes from train_5_0\n",
      "Extracted 8 keyframes from train_5_1\n",
      "Extracted 9 keyframes from train_60_0\n",
      "Extracted 67 keyframes from train_60_1\n",
      "Extracted 37 keyframes from train_60_2\n",
      "Extracted 19 keyframes from train_6_0\n",
      "Extracted 1 keyframes from train_6_1\n",
      "Extracted 2 keyframes from train_6_2\n",
      "Extracted 2 keyframes from train_6_3\n",
      "Extracted 19 keyframes from train_6_4\n",
      "Extracted 7 keyframes from train_6_5\n",
      "Extracted 4 keyframes from train_7_0\n",
      "Extracted 2 keyframes from train_7_1\n",
      "Extracted 4 keyframes from train_7_2\n",
      "Extracted 11 keyframes from train_7_3\n",
      "Extracted 6 keyframes from train_8_0\n",
      "Extracted 2 keyframes from train_8_1\n",
      "Extracted 2 keyframes from train_8_2\n",
      "Extracted 2 keyframes from train_8_3\n",
      "Extracted 1 keyframes from train_8_4\n",
      "Extracted 2 keyframes from train_8_5\n",
      "Extracted 12 keyframes from train_9_0\n",
      "Extracted 18 keyframes from train_9_1\n",
      "Extracted 6 keyframes from train_9_2\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "def calculate_ssim(frame1, frame2):\n",
    "    gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    return ssim(gray1, gray2)\n",
    "\n",
    "def extract_keyframes(video_path, output_folder, ssim_threshold=0.02):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    ret, prev_frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(f\"Error reading {video_path}\")\n",
    "        return\n",
    "    \n",
    "    video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    video_output_path = os.path.join(output_folder, video_name)\n",
    "    os.makedirs(video_output_path, exist_ok=True)\n",
    "\n",
    "    keyframes = []\n",
    "    prev_ssim = None\n",
    "    frame_idx = 0\n",
    "\n",
    "    while ret:\n",
    "        ret, curr_frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        ssim_value = calculate_ssim(prev_frame, curr_frame)\n",
    "\n",
    "        if prev_ssim is not None:\n",
    "            diff = abs(ssim_value - prev_ssim)\n",
    "            if diff > ssim_threshold:  # Significant change detected\n",
    "                keyframes.append((frame_idx, curr_frame))\n",
    "                cv2.imwrite(f\"{video_output_path}/keyframe_{frame_idx}.jpg\", curr_frame)\n",
    "\n",
    "        prev_ssim = ssim_value\n",
    "        prev_frame = curr_frame\n",
    "        frame_idx += 1\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"Extracted {len(keyframes)} keyframes from {video_name}\")\n",
    "\n",
    "def process_videos_in_folder(folder_path, output_folder, ssim_threshold=0.02):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    video_files = [f for f in os.listdir(folder_path) if f.endswith(('.mp4', '.avi', '.mov', '.mkv'))]\n",
    "    \n",
    "    for video_file in video_files:\n",
    "        video_path = os.path.join(folder_path, video_file)\n",
    "        extract_keyframes(video_path, output_folder, ssim_threshold)\n",
    "\n",
    "input_folder = r\"C:\\Users\\SUHAANI SACHDEVA\\OneDrive - Plaksha University\\MLPR raw data(video)\\test_1\"\n",
    "output_folder = r\"C:\\Users\\SUHAANI SACHDEVA\\OneDrive - Plaksha University\\MLPR raw data(video)\\keyframe_output1\"\n",
    "\n",
    "process_videos_in_folder(input_folder, output_folder, ssim_threshold=0.02)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ee1458b9-0a4a-43cd-81c7-7b0af543070e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2760 keyframes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "model = resnet50(pretrained=True)\n",
    "model = torch.nn.Sequential(*list(model.children())[:-1])  # Remove final classification layer\n",
    "model.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def extract_features_from_folder(root_folder):\n",
    "    feature_dict = {}\n",
    "\n",
    "    # Loop through each subfolder (one per video)\n",
    "    for subfolder in os.listdir(root_folder):\n",
    "        subfolder_path = os.path.join(root_folder, subfolder)\n",
    "\n",
    "        # Skip if not a folder or if it's a Jupyter checkpoint\n",
    "        if not os.path.isdir(subfolder_path) or subfolder.startswith(\".ipynb_checkpoints\"):\n",
    "            print(f\"Skipping {subfolder_path}\")\n",
    "            continue  \n",
    "\n",
    "        # Loop through images inside the subfolder\n",
    "        for img_name in os.listdir(subfolder_path):\n",
    "            img_path = os.path.join(subfolder_path, img_name)\n",
    "\n",
    "            try:\n",
    "                img = Image.open(img_path).convert(\"RGB\")\n",
    "                img_tensor = transform(img).unsqueeze(0)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    features = model(img_tensor).squeeze().numpy()\n",
    "\n",
    "                feature_dict[f\"{subfolder}/{img_name}\"] = features  # Store with subfolder name\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping {img_path} due to error: {e}\")\n",
    "\n",
    "    return feature_dict\n",
    "\n",
    "root_folder = r\"C:\\Users\\SUHAANI SACHDEVA\\OneDrive - Plaksha University\\MLPR raw data(video)\\keyframe_output1\"  # The folder containing subfolders for each video\n",
    "extracted_features = extract_features_from_folder(root_folder)\n",
    "\n",
    "if extracted_features:\n",
    "    np.save(r\"C:\\Users\\SUHAANI SACHDEVA\\OneDrive - Plaksha University\\MLPR raw data(video)\\keyframe_features.npy\", extracted_features)\n",
    "    print(f\"Saved {len(extracted_features)} keyframes.\")\n",
    "else:\n",
    "    print(\"No features extracted. Check your dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e33e5ceb-c3f8-41e7-a90a-b9014ca22c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2760 keyframes.\n",
      "Sample filenames: ['train_10_0/keyframe_106.jpg', 'train_10_0/keyframe_126.jpg', 'train_10_0/keyframe_142.jpg', 'train_10_0/keyframe_143.jpg', 'train_10_0/keyframe_16.jpg']\n",
      "Feature vector shape: (2048,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "features1 = np.load(r\"C:\\Users\\SUHAANI SACHDEVA\\OneDrive - Plaksha University\\MLPR raw data(video)\\keyframe_features.npy\", allow_pickle=True).item()\n",
    "\n",
    "print(f\"Loaded {len(features1)} keyframes.\")\n",
    "print(\"Sample filenames:\", list(features1.keys())[:5])  # Show some filenames\n",
    "print(f\"Feature vector shape: {features1[list(features1.keys())[0]].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cda88e1-2e33-4df6-a8b4-02b9072d1e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of keyframes stored: 2760\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of keyframes stored: {len(features1)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d174bfc6-42f8-42d4-9ba7-84b1304612a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample filenames: ['train_10_0/keyframe_106.jpg', 'train_10_0/keyframe_126.jpg', 'train_10_0/keyframe_142.jpg', 'train_10_0/keyframe_143.jpg', 'train_10_0/keyframe_16.jpg']\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample filenames:\", list(features1.keys())[:5])  # Show first 5 filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b41c95a2-a585-4c7f-bc3b-4f5fbe40beb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vector shape for train_10_0/keyframe_106.jpg: (2048,)\n",
      "Feature vector sample: [0.23634759 0.45235515 0.6857673  0.17497617 0.96632326 0.18178609\n",
      " 0.39257213 0.07639606 0.23744649 0.17123288]\n"
     ]
    }
   ],
   "source": [
    "sample_filename = list(features1.keys())[0]  \n",
    "print(f\"Feature vector shape for {sample_filename}: {features1[sample_filename].shape}\")\n",
    "print(f\"Feature vector sample: {features1[sample_filename][:10]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf72e1bc-da7a-4333-adac-3b323ca429e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2760 keyframes to CSV.\n"
     ]
    }
   ],
   "source": [
    "if features1:\n",
    "    # Convert to a DataFrame\n",
    "    df = pd.DataFrame(features1)\n",
    "    \n",
    "    # Save to CSV\n",
    "    csv_path = r\"C:\\Users\\SUHAANI SACHDEVA\\OneDrive - Plaksha University\\MLPR raw data(video)\\keyframe_features.csv\"\n",
    "    df.to_csv(csv_path, index=False, header=False)\n",
    "\n",
    "    print(f\"Saved {len(features1)} keyframes to CSV.\")\n",
    "else:\n",
    "    print(\"No features extracted. Check your dataset.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d294dc7-4db4-4dce-ba97-e9bddd85582b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated averaged features for 215 videos.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def average_features(features_dict):\n",
    "    video_features = {}\n",
    "    \n",
    "    # Group by video\n",
    "    video_groups = {}\n",
    "    for key, value in features_dict.items():\n",
    "        video_name = key.split('/')[0]  # Extract video name from path\n",
    "        if video_name not in video_groups:\n",
    "            video_groups[video_name] = []\n",
    "        video_groups[video_name].append(value)\n",
    "    \n",
    "    # Calculate average for each video\n",
    "    for video_name, features in video_groups.items():\n",
    "        avg_feature = np.mean(features, axis=0)\n",
    "        video_features[video_name] = avg_feature\n",
    "    \n",
    "    return video_features\n",
    "\n",
    "averaged_features = average_features(features1)\n",
    "print(f\"Generated averaged features for {len(averaged_features)} videos.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b387291d-085a-4eac-aa51-3aeef186a194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged video features saved to C:\\Users\\SUHAANI SACHDEVA\\OneDrive - Plaksha University\\MLPR raw data(video)\\averaged_video_features.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def save_to_csv(video_features, save_path):\n",
    "    # Convert the dictionary to a DataFrame\n",
    "    data = []\n",
    "    for video_name, features in video_features.items():\n",
    "        data.append([video_name] + features.tolist())\n",
    "    \n",
    "    # Create DataFrame with video names and feature columns\n",
    "    df = pd.DataFrame(data)\n",
    "    df.columns = ['Video_Name'] + [f'Feature_{i}' for i in range(len(features))]\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(f\"Averaged video features saved to {save_path}\")\n",
    "\n",
    "# Provide the save path\n",
    "csv_path = r\"C:\\Users\\SUHAANI SACHDEVA\\OneDrive - Plaksha University\\MLPR raw data(video)\\averaged_video_features.csv\"\n",
    "save_to_csv(averaged_features, csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2775919e-4b61-4e28-b52f-9af8b8b05240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Video_Name  Feature_0  Feature_1  Feature_2  Feature_3  Feature_4  \\\n",
      "0  train_10_0   0.246169   0.484276   1.014361   0.135709   0.776419   \n",
      "1  train_10_1   0.079221   0.669667   1.269671   0.089157   0.719502   \n",
      "2  train_10_2   0.116438   0.776368   1.085773   0.079519   0.749082   \n",
      "3  train_10_3   0.056843   0.412573   0.796052   0.122650   0.839875   \n",
      "4  train_10_4   0.271404   0.596357   1.203524   0.150385   0.801657   \n",
      "\n",
      "   Feature_5  Feature_6  Feature_7  Feature_8  ...  Feature_2038  \\\n",
      "0   0.219264   0.412245   0.202597   0.320988  ...      0.144905   \n",
      "1   0.247136   0.831033   0.176537   0.151766  ...      0.097169   \n",
      "2   0.274117   0.758769   0.191616   0.158376  ...      0.039334   \n",
      "3   0.245790   0.498042   0.011412   0.142774  ...      0.077735   \n",
      "4   0.191913   0.683898   0.082871   0.174521  ...      0.177151   \n",
      "\n",
      "   Feature_2039  Feature_2040  Feature_2041  Feature_2042  Feature_2043  \\\n",
      "0      0.487792      1.471952      0.598909      0.260452      0.025930   \n",
      "1      0.305113      1.087304      0.460382      0.621818      0.030332   \n",
      "2      0.433210      1.004197      0.189493      0.849377      0.048037   \n",
      "3      0.684712      1.717615      0.530246      0.094459      0.004028   \n",
      "4      0.441296      0.947765      0.580877      0.354787      0.032221   \n",
      "\n",
      "   Feature_2044  Feature_2045  Feature_2046  Feature_2047  \n",
      "0      0.228567      0.068868      0.292588      0.035461  \n",
      "1      0.244658      0.151293      0.240725      0.240336  \n",
      "2      0.203920      0.050489      0.198126      0.109855  \n",
      "3      0.176338      0.014242      0.272969      0.011881  \n",
      "4      0.200856      0.089618      0.230653      0.072459  \n",
      "\n",
      "[5 rows x 2049 columns]\n",
      "Shape of DataFrame: (215, 2049)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load CSV\n",
    "csv_path = r\"C:\\Users\\SUHAANI SACHDEVA\\OneDrive - Plaksha University\\MLPR raw data(video)\\averaged_video_features.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Print sample data\n",
    "print(df.head())\n",
    "print(f\"Shape of DataFrame: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83823bcf-c256-479a-aa39-fd5d53158dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71960133-e267-4d1c-b4bf-355829e99066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved averaged vectors for 59 utterances to C:\\Users\\SUHAANI SACHDEVA\\OneDrive - Plaksha University\\MLPR raw data(video)\\final_averaged_features.csv\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m averaged_df\u001b[38;5;241m.\u001b[39mto_csv(output_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved averaged vectors for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(averaged_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m utterances to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mshape())\n",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV\n",
    "csv_path = r\"C:\\Users\\SUHAANI SACHDEVA\\OneDrive - Plaksha University\\MLPR raw data(video)\\averaged_video_features.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Extract utterance name by removing the suffix (e.g., train_10_0 â†’ train_10)\n",
    "df['Utterance'] = df['Video_Name'].apply(lambda x: '_'.join(x.split('_')[:2]))\n",
    "\n",
    "# Group by Utterance and calculate the mean for numeric columns only\n",
    "numeric_cols = df.drop(columns=['Video_Name', 'Utterance']).columns\n",
    "averaged_df = df.groupby('Utterance')[numeric_cols].mean().reset_index()\n",
    "\n",
    "# Save to CSV\n",
    "output_path = r\"C:\\Users\\SUHAANI SACHDEVA\\OneDrive - Plaksha University\\MLPR raw data(video)\\final_averaged_features.csv\"\n",
    "averaged_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Saved averaged vectors for {len(averaged_df)} utterances to {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
